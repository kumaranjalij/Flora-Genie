{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c26436ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from html_table_extractor.extractor import Extractor\n",
    "import pandas as pd\n",
    "import time\n",
    "import collections\n",
    "import csv\n",
    "collections.Callable = collections.abc.Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53dca0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_from_h1(soup_test):\n",
    "    # Find the first h2 tag with class \"title\"\n",
    "    div_check = soup_test.find('div', class_='invalid-input')\n",
    "    h1_tag = soup_test.find('h1', style='font-style:italic;')\n",
    "    \n",
    "    # Extract the content inside the first <i> tag within the h2 tag\n",
    "    if h1_tag:\n",
    "        h1_content = h1_tag.text.strip()\n",
    "        return h1_content\n",
    "    elif div_check:\n",
    "        return \"invalid\"\n",
    "    return \"invalid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d36a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_elements_with_colon(elements):\n",
    "    grouped_elements = []\n",
    "    current_group = []\n",
    "\n",
    "    for element in elements:\n",
    "        if ':' in element:\n",
    "            # If the element contains \":\", start a new group\n",
    "            if current_group:\n",
    "                grouped_elements.append(', '.join(current_group))\n",
    "                current_group = []\n",
    "        current_group.append(element)\n",
    "\n",
    "    # Add the last group if any\n",
    "    if current_group:\n",
    "        grouped_elements.append(', '.join(current_group))\n",
    "\n",
    "    return grouped_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea556143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_content(soup_test):\n",
    "    \n",
    "    # Find the first table tag in the parsed HTML\n",
    "    table = soup_test.find_all('dl', class_='plant-details-text')\n",
    "    \n",
    "    item_list = []\n",
    "    for dl_tag in table:\n",
    "        text_list = []\n",
    "        for item in dl_tag.descendants:\n",
    "            if isinstance(item, str):  # Check if the item is a string\n",
    "                text_list.append(item.strip())# Add the text to the list\n",
    "        item_list.extend(text_list)\n",
    "        # Filter out empty strings and print the text items\n",
    "    filtered_text = [text.lstrip('- ') for text in item_list if text and text!=',']\n",
    "    grouped_elements = group_elements_with_colon(filtered_text)\n",
    "\n",
    "    return grouped_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9eb60961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful.\n"
     ]
    }
   ],
   "source": [
    "# Define the base URL pattern for login and data scraping\n",
    "base_url = \"https://www.indiaplants.com/\"\n",
    "\n",
    "# Define the User-Agent header\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Create a session to maintain the login state\n",
    "session = requests.Session()\n",
    "\n",
    "# Login endpoint URL for existing users\n",
    "login_url = base_url + \"login-check.php\"\n",
    "\n",
    "# Login credentials\n",
    "username = \"patidarriya.04@gmail.com\"\n",
    "password = \"Rsplant123\"\n",
    "\n",
    "# Login data payload for existing users\n",
    "login_data = {\n",
    "    'userName': username,\n",
    "    'userPwd': password,\n",
    "    'action': 'Login'\n",
    "}\n",
    "\n",
    "# Send a POST request to the login endpoint to authenticate as an existing user\n",
    "login_response = session.post(login_url, data=login_data, headers=headers)\n",
    "\n",
    "# Check if the login was successful (status code 200)\n",
    "if login_response.status_code == 200:\n",
    "    print(\"Login successful.\")\n",
    "else:\n",
    "    print(f\"Failed to login. Status code: {login_response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70ccc074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the extracted data\n",
    "all_data = []\n",
    "\n",
    "invalid_plant = []\n",
    "\n",
    "# Loop through IDs from 1 to 3100+\n",
    "for herb_id in range(3201, 4001):\n",
    "    # Construct the URL with the current herb ID\n",
    "    url = base_url + f\"plant-details.php?plant={herb_id}\"\n",
    "    \n",
    "    # Send an HTTP GET request to the website with the session cookies\n",
    "    response = session.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML code using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        one_plant = []\n",
    "        pid = 'Plant_id: ' + str(herb_id)\n",
    "        plant_name = extract_content_from_h1(soup)\n",
    "        if plant_name == \"invalid\":\n",
    "            #print(f\"Failed to retrieve data for ID {herb_id}. Status code: Invalid Plant\")\n",
    "            invalid_plant.append(herb_id)\n",
    "            continue;    \n",
    "        scientific_name = 'Scientific_name: ' + plant_name\n",
    "        one_plant.append(pid)\n",
    "        one_plant.append(scientific_name)\n",
    "        one_plant.extend(extract_table_content(soup))        \n",
    "        all_data.append(one_plant)\n",
    "\n",
    "    else:\n",
    "        invalid_plant.append(herb_id)\n",
    "        print(f\"Failed to retrieve data for ID {herb_id}. Status code: {response.status_code}\")\n",
    "\n",
    "    # Adding a delay between requests to avoid rate limiting\n",
    "    time.sleep(1)  # Sleep for 1 second between requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bfca4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab798b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f395018b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(invalid_plant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ca03ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3007,\n",
       " 3020,\n",
       " 3021,\n",
       " 3022,\n",
       " 3023,\n",
       " 3047,\n",
       " 3061,\n",
       " 3087,\n",
       " 3093,\n",
       " 3103,\n",
       " 3112,\n",
       " 3113,\n",
       " 3179,\n",
       " 3196]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d83265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_to_csv(scraped_data, csv_filename):\n",
    "    # Define the header row for the CSV file\n",
    "    header = ['Plant_Id', 'Scientific_Name', 'Common_Name', 'Regional_Name', 'Category', 'Family', 'Light', 'Water', 'Primary_Grown_for', 'Flowering_Season', 'Foliage_Color', 'Height_or_Length', 'Spread_or_Width', 'Plant_Form', 'Lifespan', 'Special_Feature', 'Plant_Description', 'Growing_Tips']\n",
    "    \n",
    "    # Create and open the CSV file in write mode\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header row to the CSV file\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        for item in scraped_data:\n",
    "            # Initialize variables to store extracted information\n",
    "            pid = ''\n",
    "            scientific_name = ''\n",
    "            common_names = ''\n",
    "            regional_names = ''\n",
    "            category = ''\n",
    "            family = ''\n",
    "            light = ''\n",
    "            water = ''\n",
    "            primarily_grown_for = ''\n",
    "            flowering_season = ''\n",
    "            foliage_color = ''\n",
    "            height_or_length = ''\n",
    "            spread_or_width = ''\n",
    "            plant_form = ''\n",
    "            lifespan = ''\n",
    "            special_feature = ''\n",
    "            plant_description = ''\n",
    "            growing_tips = ''            \n",
    "            \n",
    "            # Loop through each item in the scraped data\n",
    "            for sub_item in range(len(item)):\n",
    "                # Extract information based on the content of the sub-item\n",
    "                if item[sub_item].startswith('Plant_id:'):\n",
    "                    pid = item[sub_item].split(':')[1].strip()\n",
    "                elif item[sub_item].startswith('Scientific_name:'):\n",
    "                    scientific_name = item[sub_item].split(':')[1].strip()\n",
    "                elif item[sub_item].startswith('Common name:,'):\n",
    "                    common_names = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Regional name:,'):\n",
    "                    regional_names = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Category:,'):\n",
    "                    category = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Family:,'):\n",
    "                    family = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Light:,'):\n",
    "                    light = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Water:,'):\n",
    "                    water = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Primarily grown for:,'):\n",
    "                    primarily_grown_for = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Flowering season:,'):\n",
    "                    flowering_season = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Foliage color:,'):\n",
    "                    foliage_color = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Plant Height or length:,'):\n",
    "                    height_or_length = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Plant Spread or Width:,'):\n",
    "                    spread_or_width = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Plant Form:,'):\n",
    "                    plant_form = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Estimated Life Span:,'):\n",
    "                    lifespan = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Special Character:,'):\n",
    "                    special_feature = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Plant Description:,'):\n",
    "                    plant_description = item[sub_item].split(':')[1][1:].strip()\n",
    "                elif item[sub_item].startswith('Growing tips:,'):\n",
    "                    growing_tips = item[sub_item].split(':')[1][1:].strip()\n",
    "\n",
    "            # Write the extracted information to the CSV file as a row\n",
    "            writer.writerow([pid, scientific_name, common_names, regional_names, category, family, light, water, primarily_grown_for, flowering_season, foliage_color, height_or_length, spread_or_width, plant_form, lifespan, special_feature, plant_description, growing_tips])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5591d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired CSV filename\n",
    "csv_filename = './Login_IndiaPlant/data_indiaplant_3201_3400.csv'\n",
    "\n",
    "# Call the function to extract data to CSV\n",
    "extract_data_to_csv(all_data, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff9ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.indiaplants.com/customer-login.php#3310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c5256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73b52374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logout successful.\n"
     ]
    }
   ],
   "source": [
    "# Logout endpoint URL\n",
    "logout_url = base_url + \"logout.php\"\n",
    "\n",
    "# Send a GET request to the logout endpoint to log out\n",
    "logout_response = session.get(logout_url, headers=headers)\n",
    "\n",
    "# Check if the logout was successful (status code 200)\n",
    "if logout_response.status_code == 200:\n",
    "    print(\"Logout successful.\")\n",
    "else:\n",
    "    print(f\"Failed to logout. Status code: {logout_response.status_code}\")\n",
    "\n",
    "# Close the session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee4a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
